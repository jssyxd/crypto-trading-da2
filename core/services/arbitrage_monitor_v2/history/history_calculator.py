"""
å†å²æ•°æ®è®¡ç®—å™¨

èŒè´£ï¼š
- ä»æ•°æ®åº“æå–å†å²æ•°æ®
- è®¡ç®—æ‰€æœ‰äº¤æ˜“æ‰€å¯¹çš„å¤©ç„¶ä»·å·®ï¼ˆNatural Spreadï¼‰
- å°†è®¡ç®—ç»“æœå­˜å‚¨åˆ°å†…å­˜
- è·Ÿéšå†å²æ•°æ®å­˜å‚¨é¢‘ç‡ï¼ˆå­˜å‚¨â†’è®¡ç®—â†’æä¾›ï¼‰

å¤©ç„¶ä»·å·®ï¼ˆNatural Spreadï¼‰ï¼š
- ä¸åŒäº¤æ˜“æ‰€é—´å¤©ç„¶å­˜åœ¨çš„åŸºå‡†ä»·å·®
- é€šè¿‡å†å²æ•°æ®çš„ä¸­ä½æ•°è®¡ç®—ï¼ˆä¿ç•™æ­£è´Ÿå·ï¼‰
- æ­£æ•°ï¼šå†å²ä¸Šæ­¤æ–¹å‘æœ‰åˆ©å¯å›¾
- è´Ÿæ•°ï¼šå†å²ä¸Šæ­¤æ–¹å‘æ— æ³•å¥—åˆ©

æ€§èƒ½è¦æ±‚ï¼š
- æ•°æ®åº“æŸ¥è¯¢ï¼šå¼‚æ­¥ï¼Œä¸é˜»å¡ä¸»æµç¨‹
- è®¡ç®—ç»“æœå­˜å‚¨ï¼šå†…å­˜å­˜å‚¨ï¼ŒO(1)æŸ¥è¯¢
- åŠ¨æ€æ—¶é—´çª—å£ï¼š3åˆ†é’Ÿ - 24å°æ—¶
- æ›´æ–°é¢‘ç‡ï¼šè·Ÿéšå­˜å‚¨é¢‘ç‡ï¼ˆæ¯æ¬¡å­˜å‚¨åç«‹å³è®¡ç®—ï¼‰
"""

import asyncio
import logging
import statistics
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from pathlib import Path

try:
    import aiosqlite
except ImportError:
    aiosqlite = None

# ğŸ”¥ ä½¿ç”¨ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
from core.adapters.exchanges.utils.setup_logging import LoggingConfig

logger = LoggingConfig.setup_logger(
    name=__name__,
    log_file='history_calculator.log',
    console_formatter=None,
    file_formatter='detailed',
    level=logging.INFO
)
logger.propagate = False


@dataclass
class ExchangePairResult:
    """äº¤æ˜“æ‰€å¯¹çš„è®¡ç®—ç»“æœï¼ˆå­˜å‚¨åœ¨å†…å­˜ï¼‰"""
    exchange_pair: Tuple[str, str]  # (exchange_buy, exchange_sell)
    symbol: str
    
    # è®¡ç®—ç»“æœ
    natural_spread: Optional[float] = None  # å¤©ç„¶ä»·å·®ï¼ˆç™¾åˆ†æ¯”ï¼Œå¯æ­£å¯è´Ÿï¼‰
    natural_funding_rate_diff: Optional[float] = None  # ğŸ”¥ å¤©ç„¶èµ„é‡‘è´¹ç‡å·®ï¼ˆç™¾åˆ†æ¯”ï¼Œæ°¸è¿œâ‰¥0ï¼‰
    data_points_count: int = 0  # æ•°æ®ç‚¹æ•°é‡
    window_hours: float = 0.0  # å®é™…ä½¿ç”¨çš„æ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰
    funding_rate_stable: bool = False  # å†å²èµ„é‡‘è´¹ç‡å·®ç¨³å®šæ€§ï¼ˆç¨³å®š/ä¸ç¨³å®šï¼‰
    spread_stable: bool = False  # å†å²ä»·å·®ç¨³å®šæ€§ï¼ˆç¨³å®š/ä¸ç¨³å®šï¼‰
    current_funding_rate_diff: float = 0.0  # ğŸ”¥ å·²å¼ƒç”¨ï¼šè¯·ä½¿ç”¨ natural_funding_rate_diff
    
    last_update: datetime = field(default_factory=datetime.now)


class HistoryDataCalculator:
    """å†å²æ•°æ®è®¡ç®—å™¨"""
    
    def __init__(
        self,
        db_path: str = "data/spread_history/spread_history.db",
        update_interval_minutes: int = 1,
        max_history_hours: int = 24,
        min_data_points: int = 10,
        min_runtime_minutes: float = 3.0,
        # ğŸ”¥ æ–°å¢ï¼šç¨³å®šæ€§åˆ¤æ–­å‚æ•°ï¼ˆä»é…ç½®è¯»å–ï¼‰
        funding_rate_stability_threshold: float = 0.5,
        funding_rate_min_threshold: float = 0.01,
        funding_rate_duration_ratio: float = 0.8,
        funding_rate_extreme_ratio: float = 0.1,
        funding_rate_extreme_multiplier: float = 1.5,
        spread_stability_threshold: float = 0.5,
        spread_extreme_ratio: float = 0.15,
        spread_extreme_multiplier: float = 2.0,
        enable_shared_memory: bool = True  # ğŸ”¥ æ–°å¢ï¼šæ˜¯å¦å¯ç”¨å…±äº«å†…å­˜æ–‡ä»¶
    ):
        """
        åˆå§‹åŒ–å†å²æ•°æ®è®¡ç®—å™¨
        
        Args:
            db_path: SQLiteæ•°æ®åº“è·¯å¾„
            update_interval_minutes: æ›´æ–°é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
            max_history_hours: æœ€å¤§å†å²æ•°æ®æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
            min_data_points: æœ€å°‘æ•°æ®ç‚¹è¦æ±‚
            min_runtime_minutes: æœ€å°‘è¿è¡Œæ—¶é—´è¦æ±‚ï¼ˆåˆ†é’Ÿï¼‰
            
            # ç¨³å®šæ€§åˆ¤æ–­å‚æ•°ï¼ˆå¯é…ç½®ï¼‰
            funding_rate_stability_threshold: èµ„é‡‘è´¹ç‡æ³¢åŠ¨ç³»æ•°é˜ˆå€¼
            funding_rate_min_threshold: èµ„é‡‘è´¹ç‡å·®æœ€å°é˜ˆå€¼
            funding_rate_duration_ratio: æŒç»­æ—¶é—´å æ¯”é˜ˆå€¼
            funding_rate_extreme_ratio: æç«¯æ³¢åŠ¨æ¬¡æ•°å æ¯”é˜ˆå€¼
            funding_rate_extreme_multiplier: æç«¯æ³¢åŠ¨å€æ•°
            spread_stability_threshold: ä»·å·®æ³¢åŠ¨ç³»æ•°é˜ˆå€¼
            spread_extreme_ratio: ä»·å·®æç«¯æ³¢åŠ¨æ¬¡æ•°å æ¯”é˜ˆå€¼
            spread_extreme_multiplier: ä»·å·®æç«¯æ³¢åŠ¨å€æ•°
        """
        if aiosqlite is None:
            raise ImportError("aiosqliteæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨å†å²æ•°æ®è®¡ç®—åŠŸèƒ½ã€‚è¯·è¿è¡Œ: pip install aiosqlite")
        
        self.db_path = Path(db_path)
        self.update_interval_minutes = update_interval_minutes
        self.max_history_hours = max_history_hours
        self.min_data_points = min_data_points
        self.min_runtime_minutes = min_runtime_minutes
        
        # ğŸ”¥ ç¨³å®šæ€§åˆ¤æ–­å‚æ•°ï¼ˆä»é…ç½®è¯»å–ï¼‰
        self.funding_rate_stability_threshold = funding_rate_stability_threshold
        self.funding_rate_min_threshold = funding_rate_min_threshold
        self.funding_rate_duration_ratio = funding_rate_duration_ratio
        self.funding_rate_extreme_ratio = funding_rate_extreme_ratio
        self.funding_rate_extreme_multiplier = funding_rate_extreme_multiplier
        self.spread_stability_threshold = spread_stability_threshold
        self.spread_extreme_ratio = spread_extreme_ratio
        self.spread_extreme_multiplier = spread_extreme_multiplier
        
        # ğŸ”¥ è®°å½•å®é™…è¿›ç¨‹å¯åŠ¨æ—¶é—´ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        self.process_start_time = datetime.now()
        
        # ğŸ”¥ ç³»ç»Ÿå‚è€ƒæ—¶é—´ï¼šé»˜è®¤å‘å‰é¢„ç½® max_history_hoursï¼Œç¡®ä¿é‡å¯åç«‹å³å¯ç”¨å†å²æ•°æ®
        self.system_start_time = self.process_start_time - timedelta(hours=self.max_history_hours)
        
        # å†…å­˜å­˜å‚¨ï¼šè®¡ç®—ç»“æœ
        # é”®æ ¼å¼ï¼šf"{symbol}_{exchange_buy}_{exchange_sell}"ï¼ˆå¸¦æ–¹å‘ï¼‰
        self.results: Dict[str, ExchangePairResult] = {}
        
        # æ›´æ–°ä»»åŠ¡
        self.update_task: Optional[asyncio.Task] = None
        self.running = False
        
        # ğŸ”¥ å…±äº«å†…å­˜æ–‡ä»¶é…ç½®
        self.enable_shared_memory = enable_shared_memory
        self.shared_memory_path = Path("data/spread_history/calculator_results.json")
        
        logger.info(f"âœ… [å¤©ç„¶ä»·å·®] å¤©ç„¶ä»·å·®è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“ [å¤©ç„¶ä»·å·®] æ•°æ®åº“è·¯å¾„: {self.db_path}")
        logger.info(f"â±ï¸  [å¤©ç„¶ä»·å·®] æ›´æ–°é—´éš”: {self.update_interval_minutes}åˆ†é’Ÿï¼ˆè·Ÿéšå­˜å‚¨é¢‘ç‡ï¼‰")
        logger.info(f"ğŸ“Š [å¤©ç„¶ä»·å·®] åŠ¨æ€æ—¶é—´çª—å£: {self.min_runtime_minutes}åˆ†é’Ÿ - {self.max_history_hours}å°æ—¶")
        logger.info(f"ğŸ”¢ [å¤©ç„¶ä»·å·®] æœ€å°‘æ•°æ®ç‚¹: {self.min_data_points}")
        logger.info(
            f"ğŸ• [å¤©ç„¶ä»·å·®] è¿›ç¨‹å¯åŠ¨æ—¶é—´: {self.process_start_time.strftime('%Y-%m-%d %H:%M:%S')} "
            f"(å†å²çª—å£åŸºå‡†: æœ€è¿‘ {self.max_history_hours} å°æ—¶)"
        )
    
    def _get_dynamic_window_hours(self) -> float:
        """è·å–åŠ¨æ€æ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰
        
        æ ¹æ®ç³»ç»Ÿå®é™…è¿è¡Œæ—¶é—´è‡ªåŠ¨è°ƒæ•´çª—å£å¤§å°ï¼š
        - ç³»ç»Ÿåˆšå¯åŠ¨ï¼šä½¿ç”¨å®é™…è¿è¡Œæ—¶é—´
        - ç³»ç»Ÿè¿è¡Œè¶…è¿‡24å°æ—¶ï¼šä½¿ç”¨24å°æ—¶
        
        Returns:
            å®é™…ä½¿ç”¨çš„æ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰
        """
        # è®¡ç®—å®é™…è¿è¡Œæ—¶é—´ï¼ˆå°æ—¶ï¼‰
        runtime_hours = (datetime.now() - self.system_start_time).total_seconds() / 3600
        
        # åŠ¨æ€è°ƒæ•´çª—å£ï¼ˆæœ€å°3åˆ†é’Ÿï¼Œæœ€å¤§24å°æ—¶ï¼‰
        min_hours = self.min_runtime_minutes / 60
        actual_window_hours = min(self.max_history_hours, max(min_hours, runtime_hours))
        
        return actual_window_hours
    
    async def start(self):
        """å¯åŠ¨å†å²æ•°æ®è®¡ç®—å™¨"""
        if self.running:
            return
        
        self.running = True
        self.update_task = asyncio.create_task(self._update_loop())
        logger.info("âœ… [å¤©ç„¶ä»·å·®] å¤©ç„¶ä»·å·®è®¡ç®—å™¨å·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢å†å²æ•°æ®è®¡ç®—å™¨"""
        self.running = False
        
        if self.update_task:
            self.update_task.cancel()
            try:
                await self.update_task
            except asyncio.CancelledError:
                pass
        
        logger.info("ğŸ›‘ [å¤©ç„¶ä»·å·®] å¤©ç„¶ä»·å·®è®¡ç®—å™¨å·²åœæ­¢")
    
    async def _write_to_shared_memory(self):
        """ğŸ”¥ å°†è®¡ç®—ç»“æœå†™å…¥å…±äº«å†…å­˜æ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰"""
        try:
            import json
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self.shared_memory_path.parent.mkdir(parents=True, exist_ok=True)
            
            # åºåˆ—åŒ–ç»“æœ
            serialized_results = {
                "last_update": datetime.now().isoformat(),
                "system_start_time": self.system_start_time.isoformat(),
                "results_count": len(self.results),
                "results": {}
            }
            
            for key, result in self.results.items():
                exchange_buy, exchange_sell = result.exchange_pair
                serialized_results["results"][key] = {
                    "symbol": result.symbol,
                    "exchange_buy": exchange_buy,
                    "exchange_sell": exchange_sell,
                    "natural_spread": result.natural_spread,
                    "natural_funding_rate_diff": result.natural_funding_rate_diff,
                    "data_points_count": result.data_points_count,
                    "window_hours": result.window_hours,
                    "funding_rate_stable": result.funding_rate_stable,
                    "spread_stable": result.spread_stable,
                    "last_update": result.last_update.isoformat() if result.last_update else None
                }
            
            # å†™å…¥æ–‡ä»¶ï¼ˆä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ + åŸå­æ›¿æ¢ï¼Œé¿å…è¯»å–æ—¶æ–‡ä»¶ä¸å®Œæ•´ï¼‰
            temp_path = self.shared_memory_path.with_suffix('.tmp')
            with open(temp_path, 'w', encoding='utf-8') as f:
                json.dump(serialized_results, f, indent=2, ensure_ascii=False)
            
            # åŸå­æ›¿æ¢
            temp_path.replace(self.shared_memory_path)
            
            logger.debug(f"âœ… [å…±äº«å†…å­˜] å·²å†™å…¥è®¡ç®—ç»“æœ: {len(self.results)} ç»„")
            
        except Exception as e:
            logger.error(f"âŒ [å…±äº«å†…å­˜] å†™å…¥å¤±è´¥: {e}", exc_info=True)
    
    async def _update_loop(self):
        """æ›´æ–°å¾ªç¯ï¼ˆè·Ÿéšå­˜å‚¨é¢‘ç‡ï¼‰"""
        while self.running:
            try:
                await asyncio.sleep(self.update_interval_minutes * 60)
                
                if not self.running:
                    break
                
                # ğŸ”¥ ä¸ºæœ¬è½®è®¡ç®—å‡†å¤‡å®¹å™¨ï¼ˆå…ˆä¿ç•™ä¸Šä¸€è½®ç»“æœï¼Œè‹¥æœ¬è½®æ— æ•°æ®åˆ™å¤ç”¨ï¼‰
                previous_results = self.results
                new_results: Dict[str, ExchangePairResult] = {}
                previous_count = len(previous_results)

                # è·å–åŠ¨æ€æ—¶é—´çª—å£
                window_hours = self._get_dynamic_window_hours()
                runtime_minutes = (datetime.now() - self.system_start_time).total_seconds() / 60
                old_count = previous_count
                
                logger.info(
                    f"\n{'='*60}\n"
                    f"ğŸ”„ [å¤©ç„¶ä»·å·®] å¼€å§‹æ–°ä¸€è½®è®¡ç®—\n"
                    f"   ç³»ç»Ÿè¿è¡Œæ—¶é—´: {runtime_minutes:.1f}åˆ†é’Ÿ\n"
                    f"   åŠ¨æ€æ—¶é—´çª—å£: {window_hours:.2f}å°æ—¶\n"
                    f"   æ¸…ç©ºæ—§æ•°æ®: {old_count} ä¸ª\n"
                    f"{'='*60}"
                )
                
                # è·å–æ‰€æœ‰äº¤æ˜“å¯¹å’Œäº¤æ˜“æ‰€ï¼ˆä»æ•°æ®åº“æŸ¥è¯¢ï¼‰
                symbols_exchanges = await self._get_symbols_exchanges()
                
                if not symbols_exchanges:
                    logger.warning("âš ï¸ [å¤©ç„¶ä»·å·®] æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°å†å²æ•°æ®")
                    continue
                
                # æ›´æ–°æ‰€æœ‰äº¤æ˜“å¯¹çš„è®¡ç®—ç»“æœ
                total_directions = 0
                for symbol, exchanges in symbols_exchanges.items():
                    if len(exchanges) < 2:
                        continue
                    
                    directions_count = await self._update_calculated_results(symbol, exchanges, new_results)
                    total_directions += directions_count

                if new_results:
                    self.results = new_results
                    success_count = len(new_results)
                    insufficient_count = max(total_directions - success_count, 0)
                else:
                    # æœ¬è½®æœªèƒ½è·å¾—æ–°ç»“æœï¼Œå°è¯•æ²¿ç”¨ä¸Šä¸€è½®
                    if previous_results:
                        self.results = previous_results
                        success_count = previous_count
                        insufficient_count = max(total_directions - success_count, 0)
                        logger.warning("âš ï¸ [å¤©ç„¶ä»·å·®] æœ¬è½®å†å²æ•°æ®ä¸è¶³ï¼Œæ²¿ç”¨ä¸Šä¸€è½®è®¡ç®—ç»“æœ")
                    else:
                        self.results = {}
                        success_count = 0
                        insufficient_count = total_directions
                        logger.warning("âš ï¸ [å¤©ç„¶ä»·å·®] å†å²æ•°æ®åº“æš‚æ— å¯ç”¨æ•°æ®ï¼Œæ— æ³•æä¾›å¤©ç„¶ä»·å·®ç»“æœ")
                
                logger.info(
                    f"\n{'='*60}\n"
                    f"âœ… [å¤©ç„¶ä»·å·®] è®¡ç®—å®Œæˆå¹¶æä¾›æ–°æ•°æ®\n"
                    f"   äº¤æ˜“å¯¹æ•°é‡: {len(symbols_exchanges)}\n"
                    f"   äº¤æ˜“æ‰€ç»„åˆæ–¹å‘: {total_directions} ä¸ª\n"
                    f"   æˆåŠŸè®¡ç®—: {success_count} ä¸ª\n"
                    f"   æ•°æ®ä¸è¶³: {insufficient_count} ä¸ª\n"
                    f"{'='*60}\n"
                )
                
                # ğŸ”¥ å†™å…¥å…±äº«å†…å­˜æ–‡ä»¶ï¼ˆä¾›ç›‘æ§å·¥å…·è¯»å–ï¼‰
                if self.enable_shared_memory:
                    await self._write_to_shared_memory()
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ [å¤©ç„¶ä»·å·®] æ›´æ–°å¾ªç¯é”™è¯¯: {e}", exc_info=True)
    
    async def _get_symbols_exchanges(self) -> Dict[str, List[str]]:
        """ä»æ•°æ®åº“è·å–æ‰€æœ‰äº¤æ˜“å¯¹å’Œäº¤æ˜“æ‰€åˆ—è¡¨"""
        if not self.db_path.exists():
            return {}
        
        symbols_exchanges: Dict[str, List[str]] = {}
        
        try:
            async with aiosqlite.connect(self.db_path) as db:
                # æŸ¥è¯¢æ‰€æœ‰å”¯ä¸€çš„(symbol, exchange_buy, exchange_sell)ç»„åˆ
                async with db.execute("""
                    SELECT DISTINCT symbol, exchange_buy, exchange_sell
                    FROM spread_history_sampled
                    WHERE timestamp >= datetime('now', '-' || ? || ' hours')
                """, (self.max_history_hours,)) as cursor:
                    async for row in cursor:
                        symbol, exchange_buy, exchange_sell = row
                        if symbol not in symbols_exchanges:
                            symbols_exchanges[symbol] = []
                        if exchange_buy not in symbols_exchanges[symbol]:
                            symbols_exchanges[symbol].append(exchange_buy)
                        if exchange_sell not in symbols_exchanges[symbol]:
                            symbols_exchanges[symbol].append(exchange_sell)
        except Exception as e:
            logger.error(f"âŒ [å†å²è®¡ç®—] è·å–äº¤æ˜“å¯¹å’Œäº¤æ˜“æ‰€åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        
        return symbols_exchanges
    
    async def _update_calculated_results(
        self,
        symbol: str,
        exchanges: List[str],
        results_container: Dict[str, ExchangePairResult],
    ) -> int:
        """æ›´æ–°æŒ‡å®šäº¤æ˜“å¯¹çš„æ‰€æœ‰äº¤æ˜“æ‰€å¯¹çš„è®¡ç®—ç»“æœ
        
        Returns:
            è®¡ç®—çš„æ–¹å‘æ•°é‡
        """
        # è®¡ç®—æ‰€æœ‰äº¤æ˜“æ‰€å¯¹ï¼ˆæ¯ä¸ªç»„åˆ2ä¸ªæ–¹å‘ï¼‰
        from itertools import combinations
        directions_count = 0
        
        for ex1, ex2 in combinations(exchanges, 2):
            await self._calculate_pair_result(symbol, ex1, ex2, results_container)
            await self._calculate_pair_result(symbol, ex2, ex1, results_container)
            directions_count += 2
        
        return directions_count
    
    async def _calculate_pair_result(
        self,
        symbol: str,
        exchange_buy: str,
        exchange_sell: str,
        results_container: Dict[str, ExchangePairResult],
    ):
        """è®¡ç®—æŒ‡å®šäº¤æ˜“æ‰€å¯¹çš„å¤©ç„¶ä»·å·®
        
        Args:
            symbol: äº¤æ˜“å¯¹
            exchange_buy: ä¹°å…¥äº¤æ˜“æ‰€
            exchange_sell: å–å‡ºäº¤æ˜“æ‰€
        """
        pair_key = f"{symbol}_{exchange_buy}_{exchange_sell}"
        
        # è·å–åŠ¨æ€æ—¶é—´çª—å£
        window_hours = self._get_dynamic_window_hours()
        
        # ä»æ•°æ®åº“æå–å†å²æ•°æ®ï¼ˆç‰¹å®šæ–¹å‘ï¼‰
        raw_data = await self._get_history_data_dynamic(
            symbol, exchange_buy, exchange_sell, window_hours
        )
        
        if not raw_data:
            # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œä¸å­˜å‚¨ï¼ˆè·³è¿‡ï¼‰
            logger.debug(
                f"âš ï¸ [å¤©ç„¶ä»·å·®] {symbol} {exchange_buy}â†’{exchange_sell}: "
                f"æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°å†å²æ•°æ®"
            )
            return
        
        # æå–ä»·å·®å†å²ï¼ˆä¿ç•™æ­£è´Ÿå·ï¼‰
        spread_history = [row.get('spread_pct', 0.0) for row in raw_data]
        data_points = len(spread_history)
        
        # æ£€æŸ¥æ•°æ®ç‚¹æ•°é‡
        if data_points < self.min_data_points:
            logger.debug(
                f"âš ï¸ [å¤©ç„¶ä»·å·®] {symbol} {exchange_buy}â†’{exchange_sell}: "
                f"æ•°æ®ç‚¹ä¸è¶³ï¼ˆ{data_points} < {self.min_data_points}ï¼‰"
            )
            return
        
        # ğŸ”¥ è®¡ç®—å¤©ç„¶ä»·å·®ï¼šä¸­ä½æ•°ï¼ˆä¿ç•™æ­£è´Ÿå·ï¼‰
        natural_spread = statistics.median(spread_history)
        
        # ğŸ”¥ è®¡ç®—èµ„é‡‘è´¹ç‡å·®å†å²
        funding_rate_diff_history = [
            row.get('funding_rate_diff') for row in raw_data
            if row.get('funding_rate_diff') is not None
        ]
        
        # ğŸ”¥ è®¡ç®—å¤©ç„¶èµ„é‡‘è´¹ç‡å·®ï¼šä¸­ä½æ•°ï¼ˆæ°¸è¿œâ‰¥0ï¼Œå› ä¸ºå­˜å‚¨çš„æ˜¯ç»å¯¹å€¼å·®å€¼ï¼‰
        # æ•°å­¦è§„åˆ™ï¼šæ•°å€¼æ›´å¤§çš„ - æ•°å€¼æ›´å°çš„ = å·®å€¼
        # ä¾‹å¦‚ï¼š+1% - (-1%) = 2%ï¼Œ+2% - +1% = 1%ï¼Œ-1% - (-2%) = 1%
        natural_funding_rate_diff = None
        if len(funding_rate_diff_history) >= self.min_data_points:
            natural_funding_rate_diff = statistics.median(funding_rate_diff_history)
        
        # è®¡ç®—ç¨³å®šæ€§
        funding_rate_stable = self._calculate_funding_rate_stability(
            funding_rate_diff_history
        ) if len(funding_rate_diff_history) >= self.min_data_points else False
        
        spread_stable = self._calculate_spread_stability_v2(
            spread_history
        )
        
        # ğŸ”¥ ä¿æŒå‘åå…¼å®¹ï¼ˆå·²å¼ƒç”¨ï¼‰
        current_funding_rate_diff = (
            funding_rate_diff_history[-1]
            if funding_rate_diff_history else 0.0
        )
        
        # ğŸ”¥ å­˜å‚¨åˆ°å†…å­˜
        results_container[pair_key] = ExchangePairResult(
            exchange_pair=(exchange_buy, exchange_sell),
            symbol=symbol,
            natural_spread=natural_spread,
            natural_funding_rate_diff=natural_funding_rate_diff,  # ğŸ”¥ æ–°å¢
            data_points_count=data_points,
            window_hours=window_hours,
            funding_rate_stable=funding_rate_stable,
            spread_stable=spread_stable,
            current_funding_rate_diff=current_funding_rate_diff,  # ğŸ”¥ å·²å¼ƒç”¨ï¼Œä¿ç•™å…¼å®¹æ€§
            last_update=datetime.now()
        )
    
        # ğŸ”¥ è¯¦ç»†æ—¥å¿—
        spread_direction_str = "é•¿æœŸæœ‰åˆ©" if natural_spread > 0 else ("é•¿æœŸäºæŸ" if natural_spread < 0 else "åŸºæœ¬å¹³è¡¡")
        
        # ğŸ”¥ èµ„é‡‘è´¹ç‡å·®æè¿°ï¼ˆæ°¸è¿œâ‰¥0ï¼Œè¡¨ç¤ºç»å¯¹å€¼å·®å¼‚ï¼‰
        funding_description_str = "æ— æ•°æ®"
        if natural_funding_rate_diff is not None:
            if natural_funding_rate_diff > 0.02:  # å¤§äº0.02%ï¼Œæœ‰æ˜æ˜¾å·®å¼‚
                funding_description_str = "æœ‰æ˜æ˜¾å·®å¼‚"
            elif natural_funding_rate_diff > 0.005:  # å¤§äº0.005%ï¼Œæœ‰å·®å¼‚
                funding_description_str = "æœ‰å·®å¼‚"
            else:
                funding_description_str = "å·®å¼‚å¾ˆå°"
        
        # ğŸ”¥ æ„å»ºæ—¥å¿—å­—ç¬¦ä¸²
        funding_rate_line = (
            f"   å¤©ç„¶èµ„é‡‘è´¹ç‡å·®: {natural_funding_rate_diff:.6f}% ({funding_description_str})"
            if natural_funding_rate_diff is not None
            else "   å¤©ç„¶èµ„é‡‘è´¹ç‡å·®: æ— æ•°æ®"
        )
        
        logger.info(
            f"ğŸ“Š [å¤©ç„¶æ•°æ®] {symbol} {exchange_buy}â†’{exchange_sell}\n"
            f"   å¤©ç„¶ä»·å·®: {natural_spread:+.4f}% ({spread_direction_str})\n"
            f"{funding_rate_line}\n"
            f"   æ•°æ®ç‚¹æ•°: {data_points}\n"
            f"   æ—¶é—´çª—å£: {window_hours:.2f}å°æ—¶\n"
            f"   èµ„é‡‘è´¹ç‡ç¨³å®š: {'âœ… æ˜¯' if funding_rate_stable else 'âŒ å¦'}\n"
            f"   ä»·å·®ç¨³å®š: {'âœ… æ˜¯' if spread_stable else 'âŒ å¦'}"
        )
    
    async def _get_history_data_dynamic(
        self,
        symbol: str,
        exchange_buy: str,
        exchange_sell: str,
        window_hours: float
    ) -> List[Dict]:
        """ä»æ•°æ®åº“è·å–å†å²æ•°æ®ï¼ˆåŠ¨æ€æ—¶é—´çª—å£ï¼‰
        
        Args:
            symbol: äº¤æ˜“å¯¹
            exchange_buy: ä¹°å…¥äº¤æ˜“æ‰€
            exchange_sell: å–å‡ºäº¤æ˜“æ‰€
            window_hours: æ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰
        
        Returns:
            å†å²æ•°æ®åˆ—è¡¨
        """
        if not self.db_path.exists():
            return []
        
        cutoff_time = datetime.now() - timedelta(hours=window_hours)
        
        try:
            async with aiosqlite.connect(self.db_path) as db:
                async with db.execute("""
                    SELECT 
                        spread_pct,
                        funding_rate_diff,
                        timestamp
                    FROM spread_history_sampled
                    WHERE symbol = ?
                      AND exchange_buy = ?
                      AND exchange_sell = ?
                      AND timestamp >= ?
                    ORDER BY timestamp ASC
                """, (symbol, exchange_buy, exchange_sell, cutoff_time.isoformat())) as cursor:
                    rows = await cursor.fetchall()
                    return [
                        {
                            'spread_pct': row[0],
                            'funding_rate_diff': row[1],
                            'timestamp': row[2]
                        }
                        for row in rows
                    ]
        except Exception as e:
            logger.error(
                f"âŒ [å¤©ç„¶ä»·å·®] è·å–å†å²æ•°æ®å¤±è´¥: {symbol} {exchange_buy}â†’{exchange_sell}: {e}",
                exc_info=True
            )
            return []
    
    def _calculate_funding_rate_stability(
        self,
        funding_rate_diff_history: List[float]
    ) -> bool:
        """
        è®¡ç®—å†å²èµ„é‡‘è´¹ç‡å·®ç¨³å®šæ€§ï¼ˆä»é…ç½®è¯»å–å‚æ•°ï¼‰
        
        åˆ¤æ–­é€»è¾‘ï¼š
        1. æŒç»­æ—¶é—´ç¨³å®šæ€§ï¼šèµ„é‡‘è´¹ç‡å·® â‰¥ min_threshold çš„æ—¶é—´å æ¯” â‰¥ duration_ratio
        2. æ³¢åŠ¨å¹…åº¦ç¨³å®šæ€§ï¼šæ³¢åŠ¨ç³»æ•°ï¼ˆæ ‡å‡†å·®/å¹³å‡å€¼ï¼‰â‰¤ stability_threshold
        3. è¶‹åŠ¿ç¨³å®šæ€§ï¼šæç«¯æ³¢åŠ¨æ¬¡æ•° â‰¤ extreme_ratio
        
        Args:
            funding_rate_diff_history: èµ„é‡‘è´¹ç‡å·®å†å²æ•°æ®
        
        Returns:
            æ˜¯å¦ç¨³å®š
        """
        # ğŸ”¥ ä½¿ç”¨é…ç½®çš„æœ€å°‘æ•°æ®ç‚¹è¦æ±‚
        if len(funding_rate_diff_history) < self.min_data_points:
            return False
        
        try:
            # 1. æŒç»­æ—¶é—´ç¨³å®šæ€§ï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼‰
            above_threshold_count = sum(
                1 for diff in funding_rate_diff_history
                if diff >= self.funding_rate_min_threshold  # ğŸ”¥ ä»é…ç½®è¯»å–
            )
            duration_ratio = above_threshold_count / len(funding_rate_diff_history)
            duration_stable = duration_ratio >= self.funding_rate_duration_ratio  # ğŸ”¥ ä»é…ç½®è¯»å–
            
            # 2. æ³¢åŠ¨å¹…åº¦ç¨³å®šæ€§ï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼‰
            mean_diff = statistics.mean(funding_rate_diff_history)
            if mean_diff == 0:
                return False
            
            std_diff = statistics.stdev(funding_rate_diff_history) if len(funding_rate_diff_history) > 1 else 0
            volatility_coefficient = abs(std_diff / mean_diff) if mean_diff != 0 else float('inf')
            volatility_stable = volatility_coefficient <= self.funding_rate_stability_threshold  # ğŸ”¥ ä»é…ç½®è¯»å–
            
            # 3. è¶‹åŠ¿ç¨³å®šæ€§ï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼‰
            if len(funding_rate_diff_history) > 1:
                changes = [
                    abs(funding_rate_diff_history[i] - funding_rate_diff_history[i-1])
                    for i in range(1, len(funding_rate_diff_history))
                ]
                avg_change = statistics.mean(changes) if changes else 0
                extreme_changes = sum(
                    1 for change in changes
                    if change > avg_change * self.funding_rate_extreme_multiplier  # ğŸ”¥ ä»é…ç½®è¯»å–
                )
                trend_stable = extreme_changes <= len(funding_rate_diff_history) * self.funding_rate_extreme_ratio  # ğŸ”¥ ä»é…ç½®è¯»å–
            else:
                trend_stable = True
            
            # ç»¼åˆåˆ¤æ–­ï¼šä¸‰ä¸ªæ¡ä»¶éƒ½æ»¡è¶³æ‰ç®—ç¨³å®š
            return duration_stable and volatility_stable and trend_stable
            
        except Exception as e:
            logger.error(f"âŒ [å†å²è®¡ç®—] è®¡ç®—èµ„é‡‘è´¹ç‡å·®ç¨³å®šæ€§å¤±è´¥: {e}", exc_info=True)
            return False
    
    def _calculate_spread_stability_v2(
        self,
        spread_history: List[float]
    ) -> bool:
        """
        è®¡ç®—å†å²ä»·å·®ç¨³å®šæ€§ï¼ˆV2ç‰ˆæœ¬ï¼Œæ”¯æŒæ­£è´Ÿä»·å·®ï¼Œä»é…ç½®è¯»å–å‚æ•°ï¼‰
        
        åˆ¤æ–­é€»è¾‘ï¼š
        1. æ³¢åŠ¨èŒƒå›´ç¨³å®šæ€§ï¼šæ ‡å‡†å·®/ç»å¯¹å€¼å¹³å‡å€¼ â‰¤ stability_threshold
        2. æç«¯æ³¢åŠ¨æ£€æµ‹ï¼šæç«¯æ³¢åŠ¨æ¬¡æ•° â‰¤ extreme_ratio
        
        Args:
            spread_history: ä»·å·®å†å²æ•°æ®ï¼ˆåŒ…å«æ­£è´Ÿä»·å·®ï¼‰
        
        Returns:
            æ˜¯å¦ç¨³å®š
        """
        # ğŸ”¥ ä½¿ç”¨é…ç½®çš„æœ€å°‘æ•°æ®ç‚¹è¦æ±‚
        if len(spread_history) < self.min_data_points:
            return False
        
        try:
            # 1. æ³¢åŠ¨å¹…åº¦ç¨³å®šæ€§ï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼‰
            mean_spread = statistics.mean(spread_history)
            std_spread = statistics.stdev(spread_history) if len(spread_history) > 1 else 0
            
            # è®¡ç®—å˜å¼‚ç³»æ•°ï¼ˆä½¿ç”¨ç»å¯¹å€¼å¹³å‡ï¼‰
            abs_mean = statistics.mean([abs(s) for s in spread_history])
            if abs_mean == 0:
                return False
            
            volatility_coefficient = std_spread / abs_mean
            volatility_stable = volatility_coefficient <= self.spread_stability_threshold  # ğŸ”¥ ä»é…ç½®è¯»å–
            
            # 2. æç«¯æ³¢åŠ¨æ£€æµ‹ï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼‰
            if len(spread_history) > 1:
                changes = [
                    abs(spread_history[i] - spread_history[i-1])
                    for i in range(1, len(spread_history))
                ]
                avg_change = statistics.mean(changes) if changes else 0
                extreme_changes = sum(
                    1 for change in changes
                    if change > avg_change * self.spread_extreme_multiplier  # ğŸ”¥ ä»é…ç½®è¯»å–
                )
                extreme_stable = extreme_changes <= len(spread_history) * self.spread_extreme_ratio  # ğŸ”¥ ä»é…ç½®è¯»å–
            else:
                extreme_stable = True
            
            # ç»¼åˆåˆ¤æ–­ï¼šä¸¤ä¸ªæ¡ä»¶éƒ½æ»¡è¶³æ‰ç®—ç¨³å®š
            return volatility_stable and extreme_stable
            
        except Exception as e:
            logger.error(f"âŒ [å¤©ç„¶ä»·å·®] è®¡ç®—ä»·å·®ç¨³å®šæ€§å¤±è´¥: {e}", exc_info=True)
            return False
    
    async def get_natural_spread(
        self,
        symbol: str,
        exchange_buy: str,
        exchange_sell: str
    ) -> tuple[Optional[float], Optional[datetime]]:
        """
        è·å–å¤©ç„¶ä»·å·®ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        
        Args:
            symbol: äº¤æ˜“å¯¹
            exchange_buy: ä¹°å…¥äº¤æ˜“æ‰€
            exchange_sell: å–å‡ºäº¤æ˜“æ‰€
        
        Returns:
            (å¤©ç„¶ä»·å·®, æ›´æ–°æ—¶é—´) å…ƒç»„
            - å¤©ç„¶ä»·å·®ï¼ˆç™¾åˆ†æ¯”ï¼‰:
              * æ­£æ•°ï¼šå†å²ä¸Šæ­¤æ–¹å‘æœ‰åˆ©å¯å›¾
              * è´Ÿæ•°ï¼šå†å²ä¸Šæ­¤æ–¹å‘æ— æ³•å¥—åˆ©
              * Noneï¼šæ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—
            - æ›´æ–°æ—¶é—´ï¼šæœ€åæ›´æ–°æ—¶é—´æˆ³ï¼ˆç”¨äºæ£€æŸ¥æ•°æ®æ–°é²œåº¦ï¼‰
        """
        pair_key = f"{symbol}_{exchange_buy}_{exchange_sell}"
        result = self.results.get(pair_key)
        
        if result:
            return (result.natural_spread, result.last_update)
        else:
            return (None, None)
    
    async def get_avg_positive_spread(
        self,
        symbol: str,
        exchange1: str,
        exchange2: str
    ) -> float:
        """
        ã€å·²åºŸå¼ƒã€‘è·å–å†å²å¹³å‡æ­£æ•°ä»·å·®å€¼
        
        è¯·ä½¿ç”¨ get_natural_spread() æ›¿ä»£
        
        Args:
            symbol: äº¤æ˜“å¯¹
            exchange1: äº¤æ˜“æ‰€1
            exchange2: äº¤æ˜“æ‰€2
        
        Returns:
            å†å²å¹³å‡æ­£æ•°ä»·å·®å€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰ï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™è¿”å›0.0
        """
        logger.warning(
            f"âš ï¸ [å¤©ç„¶ä»·å·®] get_avg_positive_spread() å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ get_natural_spread()"
        )
        natural_spread, _ = await self.get_natural_spread(symbol, exchange1, exchange2)
        return natural_spread if natural_spread is not None else 0.0
    
    async def is_funding_rate_stable(
        self,
        symbol: str,
        exchange1: str,
        exchange2: str
    ) -> bool:
        """
        è·å–å†å²èµ„é‡‘è´¹ç‡å·®ç¨³å®šæ€§
        
        Args:
            symbol: äº¤æ˜“å¯¹
            exchange1: äº¤æ˜“æ‰€1
            exchange2: äº¤æ˜“æ‰€2
        
        Returns:
            æ˜¯å¦ç¨³å®šï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™è¿”å›False
        """
        pair_key = f"{symbol}_{exchange1}_{exchange2}"
        result = self.results.get(pair_key)
        return result.funding_rate_stable if result else False
    
    async def is_spread_stable(
        self,
        symbol: str,
        exchange1: str,
        exchange2: str
    ) -> bool:
        """
        è·å–å†å²ä»·å·®ç¨³å®šæ€§
        
        Args:
            symbol: äº¤æ˜“å¯¹
            exchange1: äº¤æ˜“æ‰€1
            exchange2: äº¤æ˜“æ‰€2
        
        Returns:
            æ˜¯å¦ç¨³å®šï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™è¿”å›False
        """
        pair_key = f"{symbol}_{exchange1}_{exchange2}"
        result = self.results.get(pair_key)
        return result.spread_stable if result else False
    
    async def get_natural_funding_rate_diff(
        self,
        symbol: str,
        exchange_buy: str,
        exchange_sell: str
    ) -> tuple[Optional[float], Optional[datetime]]:
        """
        è·å–å¤©ç„¶èµ„é‡‘è´¹ç‡å·®ï¼ˆNatural Funding Rate Differenceï¼‰
        
        å¤©ç„¶èµ„é‡‘è´¹ç‡å·®å®šä¹‰ï¼š
        - ä¸¤ä¸ªäº¤æ˜“æ‰€é—´çš„é•¿æœŸèµ„é‡‘è´¹ç‡å·®å¼‚ï¼ˆä¸­ä½æ•°ï¼‰
        - æ°¸è¿œ â‰¥ 0ï¼ˆç»å¯¹å€¼å·®å€¼ï¼‰
        - è®¡ç®—è§„åˆ™ï¼šæ•°å€¼æ›´å¤§çš„è´¹ç‡ - æ•°å€¼æ›´å°çš„è´¹ç‡
        
        ç¤ºä¾‹ï¼š
        - äº¤æ˜“æ‰€Aè´¹ç‡ +1%ï¼Œäº¤æ˜“æ‰€Bè´¹ç‡ +2% â†’ å·®å€¼ = |2% - 1%| = 1%
        - äº¤æ˜“æ‰€Aè´¹ç‡ -1%ï¼Œäº¤æ˜“æ‰€Bè´¹ç‡ +1% â†’ å·®å€¼ = |1% - (-1%)| = 2%
        - äº¤æ˜“æ‰€Aè´¹ç‡ -2%ï¼Œäº¤æ˜“æ‰€Bè´¹ç‡ -1% â†’ å·®å€¼ = |-1% - (-2%)| = 1%
        
        å¥—åˆ©æ–¹å‘ï¼š
        - æ•°å€¼æ›´å¤§çš„äº¤æ˜“æ‰€åšç©ºï¼ˆæ”¶å–èµ„é‡‘è´¹ç‡ï¼‰
        - æ•°å€¼æ›´å°çš„äº¤æ˜“æ‰€åšå¤šï¼ˆæ”¯ä»˜æ›´å°‘æˆ–æ”¶å–æ›´å¤šï¼‰
        
        Args:
            symbol: äº¤æ˜“å¯¹ï¼Œå¦‚ "BTC-USDC-PERP"
            exchange_buy: ä¹°å…¥äº¤æ˜“æ‰€ï¼ˆåšå¤šæ–¹ï¼‰
            exchange_sell: å–å‡ºäº¤æ˜“æ‰€ï¼ˆåšç©ºæ–¹ï¼‰
        
        Returns:
            tuple[Optional[float], Optional[datetime]]: (å¤©ç„¶èµ„é‡‘è´¹ç‡å·®, æœ€åæ›´æ–°æ—¶é—´)
            - å¦‚æœæ•°æ®ä¸è¶³æˆ–ä¸å­˜åœ¨ï¼Œè¿”å› (None, None)
            - å¦‚æœå­˜åœ¨æœ‰æ•ˆæ•°æ®ï¼Œè¿”å› (ç™¾åˆ†æ¯”å€¼ â‰¥ 0, æ›´æ–°æ—¶é—´)
        
        Example:
            natural_funding_diff, last_update = await calculator.get_natural_funding_rate_diff(
                "BTC-USDC-PERP", "backpack", "lighter"
            )
            if natural_funding_diff is not None:
                print(f"å¤©ç„¶èµ„é‡‘è´¹ç‡å·®: {natural_funding_diff:.6f}%")
                # å†³ç­–ï¼šå½“å‰èµ„é‡‘è´¹ç‡å·® > å¤©ç„¶èµ„é‡‘è´¹ç‡å·® + é˜ˆå€¼ â†’ æœ‰å¥—åˆ©æœºä¼š
        """
        pair_key = f"{symbol}_{exchange_buy}_{exchange_sell}"
        result = self.results.get(pair_key)
        
        if result and result.natural_funding_rate_diff is not None:
            return result.natural_funding_rate_diff, result.last_update
        
        return None, None
    
    async def get_current_funding_rate_diff(
        self,
        symbol: str,
        exchange1: str,
        exchange2: str
    ) -> float:
        """
        ğŸ”¥ å·²å¼ƒç”¨ï¼šè·å–å½“å‰èµ„é‡‘è´¹ç‡å·®å€¼
        
        è¯·ä½¿ç”¨ get_natural_funding_rate_diff() ä»£æ›¿
        
        Args:
            symbol: äº¤æ˜“å¯¹
            exchange1: äº¤æ˜“æ‰€1
            exchange2: äº¤æ˜“æ‰€2
        
        Returns:
            å½“å‰èµ„é‡‘è´¹ç‡å·®å€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰ï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™è¿”å›0.0
        """
        logger.warning(
            f"âš ï¸ [èµ„é‡‘è´¹ç‡å·®] get_current_funding_rate_diff() å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ get_natural_funding_rate_diff()"
        )
        pair_key = f"{symbol}_{exchange1}_{exchange2}"
        result = self.results.get(pair_key)
        return result.current_funding_rate_diff if result else 0.0
    
    def get_result_count(self) -> int:
        """è·å–å½“å‰å­˜å‚¨çš„è®¡ç®—ç»“æœæ•°é‡"""
        return len(self.results)
    
    def get_results_for_symbol(self, symbol: str) -> List[ExchangePairResult]:
        """è·å–æŒ‡å®šäº¤æ˜“å¯¹çš„æ‰€æœ‰è®¡ç®—ç»“æœ"""
        return [
            result for key, result in self.results.items()
            if result.symbol == symbol
        ]

